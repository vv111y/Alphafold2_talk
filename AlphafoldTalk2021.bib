
@misc{abdolhosseiniCellIdentityCodes2018,
  title = {Cell {{Identity Codes}}: {{Understanding Cell Identity}} from {{Gene Expression Profiles}} Using {{Deep Neural Networks}}},
  shorttitle = {Cell {{Identity Codes}}},
  author = {Abdolhosseini, Farzad and Azarkhalili, Behrooz and Maazallahi, Abbas and Kamal, Aryan and Motahari, Seyed Abolfazl and {Sharifi-Zarchi}, Ali and Chitsaz, Hamidreza},
  year = {2018},
  journal = {undefined},
  abstract = {Farzad Abdolhosseini, Behrooz Azarkhalili, Abbas Maazallahi, Aryan Kamal, Seyed Abolfazl Motahari, Ali Sharifi-Zarchi*and Hamidreza Chitsaz* Department of Computer Engineering, Sharif University of Technology, Tehran, Iran Royan Institute for Stem Cell Biology and Technology, ACECR, Tehran, Iran Department of Computer Science, Colorado State University, Fort Collins, CO, USA Corresponding authors: asharifi@sharif.ir, chitsaz@chitsazlab.org},
  howpublished = {/paper/Cell-Identity-Codes\%3A-Understanding-Cell-Identity-Abdolhosseini-Azarkhalili/4d12130604683a1e89cb6f536b2f6a7bd3323386},
  language = {en},
  annotation = {00000},
  file = {/home/will/Zotero/storage/YNRPE6SR/Abdolhosseini et al_2018_Cell Identity Codes.pdf;/home/will/Zotero/storage/MW9B9528/4d12130604683a1e89cb6f536b2f6a7bd3323386.html}
}

@article{alipanahiPredictingSequenceSpecificities2015,
  title = {Predicting the Sequence Specificities of {{DNA}}- and {{RNA}}-Binding Proteins by Deep Learning},
  author = {Alipanahi, Babak and Delong, Andrew and Weirauch, Matthew T and Frey, Brendan J},
  year = {2015},
  month = aug,
  journal = {Nature Biotechnology},
  volume = {33},
  number = {8},
  pages = {831--838},
  issn = {1087-0156, 1546-1696},
  doi = {10/f7mkrd},
  language = {en},
  annotation = {00750},
  file = {/home/will/Zotero/storage/IYXEQ9QB/Alipanahi et al. - 2015 - Predicting the sequence specificities of DNA- and .pdf}
}

@article{alquraishiEndtoendDifferentiableLearning2018,
  title = {End-to-End Differentiable Learning of Protein Structure},
  author = {AlQuraishi, Mohammed},
  year = {2018},
  month = aug,
  journal = {bioRxiv},
  pages = {265231},
  doi = {10/gc3gsf},
  abstract = {Predicting protein structure from sequence is a central challenge of biochemistry. Co-evolution methods show promise, but an explicit sequence-to-structure map remains elusive. Advances in deep learning that replace complex, human-designed pipelines with differentiable models optimized end-to-end suggest the potential benefits of similarly reformulating structure prediction. Here we report the first end-to-end differentiable model of protein structure. The model couples local and global protein structure via geometric units that optimize global geometry without violating local covalent chemistry. We test our model using two challenging tasks: predicting novel folds without co-evolutionary data and predicting known folds without structural templates. In the first task the model achieves state-of-the-art accuracy and in the second it comes within 1-2\AA; competing methods using co-evolution and experimental templates have been refined over many years and it is likely that the differentiable approach has substantial room for further improvement, with applications ranging from drug discovery to protein design.},
  copyright = {\textcopyright{} 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  language = {en},
  annotation = {00002},
  file = {/home/will/Zotero/storage/6VI5ND3J/AlQuraishi_2018_End-to-end differentiable learning of protein structure.pdf;/home/will/Zotero/storage/2HMTCCKU/265231.html}
}

@article{angermuellerDeepCpGAccuratePrediction2017,
  title = {{{DeepCpG}}: Accurate Prediction of Single-Cell {{DNA}} Methylation States Using Deep Learning},
  shorttitle = {{{DeepCpG}}},
  author = {Angermueller, Christof and Lee, Heather J. and Reik, Wolf and Stegle, Oliver},
  year = {2017},
  month = apr,
  journal = {Genome Biology},
  volume = {18},
  number = {1},
  pages = {67},
  issn = {1474-760X},
  doi = {10/gcgmcc},
  abstract = {Recent technological advances have enabled DNA methylation to be assayed at single-cell resolution. However, current protocols are limited by incomplete CpG coverage and hence methods to predict missing methylation states are critical to enable genome-wide analyses. We report DeepCpG, a computational approach based on deep neural networks to predict methylation states in single cells. We evaluate DeepCpG on single-cell methylation data from five cell types generated using alternative sequencing protocols. DeepCpG yields substantially more accurate predictions than previous methods. Additionally, we show that the model parameters can be interpreted, thereby providing insights into how sequence composition affects methylation variability.},
  annotation = {00091},
  file = {/home/will/Zotero/storage/83M29ZRA/Angermueller et al_2017_DeepCpG.pdf;/home/will/Zotero/storage/62V5IMBV/s13059-017-1189-z.html}
}

@inproceedings{angermuellerDeepLearningComputational2016,
  title = {Deep Learning for Computational Biology},
  booktitle = {Molecular Systems Biology},
  author = {Angermueller, Christof and P{\"a}rnamaa, Tanel and Parts, Leopold and Stegle, Oliver},
  year = {2016},
  doi = {10/f8xtvh},
  abstract = {Technological advances in genomics and imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples. This rapid increase in biological data dimension and acquisition rate is challenging conventional analysis strategies. Modern machine learning methods, such as deep learning, promise to leverage very large data sets for finding hidden structure within them, and for making accurate predictions. In this review, we discuss applications of this new breed of analysis approaches in regulatory genomics and cellular imaging. We provide background of what deep learning is, and the settings in which it can be successfully applied to derive biological insights. In addition to presenting specific applications and providing tips for practical use, we also highlight possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new technology.},
  keywords = {cellular imaging,Computational Biology},
  annotation = {00000},
  file = {/home/will/Zotero/storage/L5EP3QSJ/Angermueller et al_2016_Deep learning for computational biology.pdf}
}

@article{ben-bassatDeepNeuralNetwork2018,
  title = {A Deep Neural Network Approach for Learning Intrinsic Protein-{{RNA}} Binding Preferences},
  author = {{Ben-Bassat}, Ilan and Chor, Benny and Orenstein, Yaron},
  year = {2018},
  journal = {Bioinformatics},
  volume = {34},
  number = {17},
  pages = {NaN-NaN},
  doi = {10/gd9kj9},
  abstract = {Motivation The complexes formed by binding of proteins to RNAs play key roles in many biological processes, such as splicing, gene expression regulation, translation and viral replication. Understanding protein-RNA binding may thus provide important insights to the functionality and dynamics of many cellular processes. This has sparked substantial interest in exploring protein-RNA binding experimentally, and predicting it computationally. The key computational challenge is to efficiently and accurately infer protein-RNA binding models that will enable prediction of novel protein-RNA interactions to additional transcripts of interest. Results We developed DLPRB (Deep Learning for Protein-RNA Binding), a new deep neural network (DNN) approach for learning intrinsic protein-RNA binding preferences and predicting novel interactions. We present two different network architectures: a convolutional neural network (CNN), and a recurrent neural network (RNN). The novelty of our network hinges upon two key aspects: (i) the joint analysis of both RNA sequence and structure, which is represented as a probability vector of different RNA structural contexts; (ii) novel features in the architecture of the networks, such as the application of RNNs to RNA-binding prediction, and the combination of hundreds of variable-length filters in the CNN. Our results in inferring accurate RNA-binding models from high-throughput in vitro data exhibit substantial improvements, compared to all previous approaches for protein-RNA binding prediction (both DNN and non-DNN based). A more modest, yet statistically significant, improvement is achieved for in vivo binding prediction. When incorporating experimentally-measured RNA structure, compared to predicted one, the improvement on in vivo data increases. By visualizing the binding specificities, we can gain biological insights underlying the mechanism of protein RNA-binding. Availability and implementation The source code is publicly available at https://github.com/ilanbb/dlprb. Supplementary information Supplementary data are available at Bioinformatics online.},
  keywords = {Artificial neural network,Bioinformatics,Biological Neural Networks,Convolutional neural network,Deep learning,Experiment,Geographic Information Systems,High-throughput computing,Interaction,Random neural network,Recurrent neural network,RNA Binding,RNA Splicing,Source Code,Throughput,Transcript,Video-in video-out,Virus Replication},
  annotation = {00000},
  file = {/home/will/Zotero/storage/3ZCDBD28/Ben-Bassat et al_2018_A deep neural network approach for learning intrinsic protein-RNA binding.pdf}
}

@article{caoSimpleTricksConvolutional2018a,
  title = {Simple Tricks of Convolutional Neural Network Architectures Improve {{DNA}}\textendash Protein Binding Prediction},
  author = {Cao, Zhen and Zhang, Shihua},
  year = {2018},
  month = oct,
  journal = {Bioinformatics},
  doi = {10.1093/bioinformatics/bty893},
  abstract = {AbstractMotivation.  With the accumulation of DNA sequencing data, convolution neural network (CNN) based methods such as DeepBind and DeepSEA have achieved gre},
  language = {en},
  file = {/home/will/Zotero/storage/IZXPT3XI/Cao_Zhang_2018_Simple tricks of convolutional neural network architectures improve DNA–protein.pdf;/home/will/Zotero/storage/JJIJB4XN/5142724.html}
}

@article{chingtraversOpportunitiesObstaclesDeep2018,
  title = {Opportunities and Obstacles for Deep Learning in Biology and Medicine},
  author = {{Ching Travers} and {Himmelstein Daniel S.} and {Beaulieu-Jones Brett K.} and {Kalinin Alexandr A.} and {Do Brian T.} and {Way Gregory P.} and {Ferrero Enrico} and {Agapow Paul-Michael} and {Zietz Michael} and {Hoffman Michael M.} and {Xie Wei} and {Rosen Gail L.} and {Lengerich Benjamin J.} and {Israeli Johnny} and {Lanchantin Jack} and {Woloszynek Stephen} and {Carpenter Anne E.} and {Shrikumar Avanti} and {Xu Jinbo} and {Cofer Evan M.} and {Lavender Christopher A.} and {Turaga Srinivas C.} and {Alexandari Amr M.} and {Lu Zhiyong} and {Harris David J.} and {DeCaprio Dave} and {Qi Yanjun} and {Kundaje Anshul} and {Peng Yifan} and {Wiley Laura K.} and {Segler Marwin H. S.} and {Boca Simina M.} and {Swamidass S. Joshua} and {Huang Austin} and {Gitter Anthony} and {Greene Casey S.}},
  year = {2018},
  month = apr,
  journal = {Journal of The Royal Society Interface},
  volume = {15},
  number = {141},
  pages = {20170387},
  doi = {10.1098/rsif.2017.0387},
  abstract = {Deep learning describes a class of machine learning algorithms that are capable of combining raw inputs into layers of intermediate features. These algorithms have recently shown impressive results across a variety of domains. Biology and medicine are data-rich disciplines, but the data are complex and often ill-understood. Hence, deep learning techniques may be particularly well suited to solve problems of these fields. We examine applications of deep learning to a variety of biomedical problems\textemdash patient classification, fundamental biological processes and treatment of patients\textemdash and discuss whether deep learning will be able to transform these tasks or if the biomedical sphere poses unique challenges. Following from an extensive literature review, we find that deep learning has yet to revolutionize biomedicine or definitively resolve any of the most pressing challenges in the field, but promising advances have been made on the prior state of the art. Even though improvements over previous baselines have been modest in general, the recent progress indicates that deep learning methods will provide valuable means for speeding up or aiding human investigation. Though progress has been made linking a specific neural network's prediction to input features, understanding how users should interpret these models to make testable hypotheses about the system under study remains an open challenge. Furthermore, the limited amount of labelled data for training presents problems in some domains, as do legal and privacy constraints on work with sensitive health records. Nonetheless, we foresee deep learning enabling changes at both bench and bedside with the potential to transform several areas of biology and medicine.},
  file = {/home/will/Zotero/storage/5AQZIM7T/Ching Travers et al. - 2018 - Opportunities and obstacles for deep learning in b.pdf;/home/will/Zotero/storage/T49ZV7Q7/rsif.2017.html}
}

@article{choongEvaluationConvolutionaryNeural2017,
  title = {Evaluation of Convolutionary Neural Networks Modeling of {{DNA}} Sequences Using Ordinal versus One-Hot Encoding Method},
  author = {Choong, Allen Chieng Hoon and Lee, Nung Kion},
  year = {2017},
  journal = {2017 International Conference on Computer and Drone Applications (IConDA)},
  pages = {60--65},
  doi = {10/gftjxz},
  abstract = {Convolutionary neural network (CNN) is a popular choice for supervised DNA motif prediction due to its excellent performances. To employ CNN, the input DNA sequences are required to be encoded as numerical values and represented as either vectors or multi-dimensional matrices. This paper evaluated a simple and more compact ordinal encoding method versus the popular one-hot encoding for DNA sequences. We compared the performances of both encoding methods using three sets of datasets enriched with DNA motifs. We found that the ordinal encoding performs comparable to the one-hot method but with significant reduction in training time. In addition, the one-hot encoding performances were rather consistent across various datasets but would require suitable CNN configuration to perform well. The ordinal encoding with matrix representation performed best in some of the evaluated datasets. This study implied that the performances of CNN for DNA motif discovery depends on the suitable design of the sequence encoding and representation. The good performances of the ordinal encoding method demonstrates that there are still rooms for improvement for the one-hot encoding method.},
  keywords = {Artificial neural network,Biological Neural Networks,Matrix representation,Motif,Neural Network Simulation,Numerical analysis,Numerous,One-hot,Ordinal data,Ordinal Position,Performance},
  annotation = {00000}
}

@article{dejesusCapsuleNetworksProtein2018,
  title = {Capsule {{Networks}} for {{Protein Structure Classification}} and {{Prediction}}},
  author = {{de Jesus}, Dan Rosa and Cuevas, Julian and Rivera, Wilson and Crivelli, Silvia},
  year = {2018},
  month = aug,
  journal = {arXiv:1808.07475 [cs, q-bio, stat]},
  eprint = {1808.07475},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio, stat},
  abstract = {Capsule Networks have great potential to tackle problems in structural biology because of their attention to hierarchical relationships. This paper describes the implementation and application of a Capsule Network architecture to the classification of RAS protein family structures on GPU-based computational resources. The proposed Capsule Network trained on 2D and 3D structural encodings can successfully classify HRAS and KRAS structures. The Capsule Network can also classify a protein-based dataset derived from a PSI-BLAST search on sequences of KRAS and HRAS mutations. Our results show an accuracy improvement compared to traditional convolutional networks, while improving interpretability through visualization of activation vectors.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {/home/will/Zotero/storage/HPE6XQWR/de Jesus et al. - 2018 - Capsule Networks for Protein Structure Classificat.pdf;/home/will/Zotero/storage/5NSGG695/1808.html}
}

@misc{demingGeneticArchitectDiscovering2016,
  title = {Genetic {{Architect}}: {{Discovering Genomic Structure}} with {{Learned Neural Architectures}}},
  shorttitle = {Genetic {{Architect}}},
  author = {Deming, Laura and Targ, Sasha and Sauder, Nate and Almeida, Diogo and Ye, Chun Jimmie},
  year = {2016},
  journal = {undefined},
  abstract = {Each human genome is a 3 billion base pair set of encoding instructions. Decoding the genome using deep learning fundamentally differs from most tasks, as we do not know the full structure of the data and therefore cannot design architectures to suit it. As such, architectures that fit the structure of genomics should be learned not prescribed. Here, we develop a novel search algorithm, applicable across domains, that discovers an optimal architecture which simultaneously learns general genomic patterns and identifies the most important sequence motifs in predicting functional genomic outcomes. The architectures we find using this algorithm succeed at using only RNA expression data to predict gene regulatory structure, learn humaninterpretable visualizations of key sequence motifs, and surpass state-of-the-art results on benchmark genomics challenges.},
  howpublished = {/paper/Genetic-Architect\%3A-Discovering-Genomic-Structure-Deming-Targ/19c99e26e9a5060ff8d885e9725e66c4b6cb66bd},
  language = {en},
  annotation = {00000},
  file = {/home/will/Zotero/storage/BJIBBPIK/Deming et al_2016_Genetic Architect.pdf;/home/will/Zotero/storage/TTIJDSIQ/19c99e26e9a5060ff8d885e9725e66c4b6cb66bd.html}
}

@article{dillLevinthalPathwaysFunnels1997,
  title = {From {{Levinthal}} to Pathways to Funnels},
  author = {Dill, Ken A. and Chan, Hue Sun},
  year = {1997},
  month = jan,
  journal = {Nature Structural \& Molecular Biology},
  volume = {4},
  number = {1},
  pages = {10--19},
  issn = {1545-9993, 1545-9985},
  doi = {10/d2tc3c},
  language = {en},
  annotation = {02647},
  file = {/home/will/Zotero/storage/PRESJUVB/Dill and Chan - 1997 - From Levinthal to pathways to funnels.pdf}
}

@article{dysonIntrinsicallyUnstructuredProteins2005a,
  title = {Intrinsically Unstructured Proteins and Their Functions},
  author = {Dyson, H. Jane and Wright, Peter E.},
  year = {2005},
  month = mar,
  journal = {Nature Reviews Molecular Cell Biology},
  volume = {6},
  number = {3},
  pages = {197--208},
  issn = {1471-0072, 1471-0080},
  doi = {10/dz3jmr},
  abstract = {Many gene sequences in eukaryotic genomes encode entire proteins or large segments of proteins that lack a well-structured three-dimensional fold. Disordered regions can be highly conserved between species in both composition and sequence and, contrary to the traditional view that protein function equates with a stable three-dimensional structure, disordered regions are often functional, in ways that we are only beginning to discover. Many disordered segments fold on binding to their biological targets (coupled folding and binding), whereas others constitute flexible linkers that have a role in the assembly of macromolecular arrays.},
  language = {en},
  annotation = {03248},
  file = {/home/will/Zotero/storage/HZJF4ELJ/Dyson and Wright - 2005 - Intrinsically unstructured proteins and their func.pdf}
}

@article{FASTAFormat2021,
  title = {{{FASTA}} Format},
  year = {2021},
  month = may,
  journal = {Wikipedia},
  abstract = {In bioinformatics and biochemistry, the FASTA format is a text-based format for representing either nucleotide sequences or amino acid (protein) sequences, in which nucleotides or amino acids are represented using single-letter codes. The format also allows for sequence names and comments to precede the sequences. The format originates from the FASTA software package, but has now become a near universal standard in the field of bioinformatics.The simplicity of FASTA format makes it easy to manipulate and parse sequences using text-processing tools and scripting languages like the R programming language, Python, Ruby, and Perl.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  language = {en},
  annotation = {00000  Page Version ID: 1021800055}
}

@article{FileProteinStructure,
  title = {File:{{Protein}} Structure Examples.Png},
  shorttitle = {File},
  journal = {Wikipedia},
  copyright = {Creative Commons Attribution-ShareAlike License},
  language = {en},
  annotation = {00000},
  file = {/home/will/Zotero/storage/NVSIZMMH/FileProtein_structure_examples.html}
}

@inproceedings{gomesBioinformaticsApproachUnderstanding2017,
  title = {A Bioinformatics Approach for the Understanding of Membrane Protein Complexes},
  booktitle = {A Bioinformatics Approach for the Understanding of Membrane Protein Complexes},
  author = {Gomes, Ant{\'o}nio Jos{\'e} Preto Martins},
  year = {2017},
  month = sep,
  abstract = {In Life science's it is crucial characterize the structure and function of biological molecules, particularly, proteins. The structural characterization of soluble proteins, membrane proteins and diverse protein complexes, as of late, has benefitted from computational approaches' contributions. These would be essential in the case of membrane proteins. Due to their near functional ubiquity and the difficulty of their experimental study, the employment of structure prediction and interface characterization computational methods allows for broad and in-depth comprehension, fundamental if we realize membrane proteins are key targets in the pharmaceutical industry.In this master thesis, the works was divided in two different but interconnect tasks: i) the understanding of a typical example of membrane protein: G-coupled protein receptor complexes and ii) the methodological development for protein interaction characterization. As a results of the first task we list all conclusions retrieved from the modelling of complexes between GPCRs, arrestins and G-proteins with the full assessment of the surface area inter-residual distance, residue conservation, hydrogen bonds, among other characteristics. Subsequently, we proceed to identify substructures, regions, residue patterns and specific residues' relevant for complex formation between GPCRs and other proteins. The data was summarized under graphical display and made available online (http://45.32.153.74/gpcr/).  In the second part, we focused on Machine Learning algorithms' deployment in order to correctly classify protein interfacial residues, which are crucial at a structural and functional level: Hot-Spots. Based on experimental data and residue feature collection, a Hot-Spot prediction model was built, available at a free-access portal (http://milou.science.uu.nl/cgi/services/SPOTON/spoton/). We also sought to understand how the inclusion of coevolutionary features influences the performance of the developed methodologies.},
  copyright = {openAccess},
  language = {eng},
  annotation = {00000},
  file = {/home/will/Zotero/storage/R5Z7BPHM/Gomes_2017_A_bioinformatics_approach_for_the_understanding_of_membrane_protein_complexes.pdf;/home/will/Zotero/storage/TI5IHXLX/83091.html}
}

@inproceedings{hassanzadehDeeperBindEnhancingPrediction2016,
  title = {{{DeeperBind}}: {{Enhancing}} Prediction of Sequence Specificities of {{DNA}} Binding Proteins},
  shorttitle = {{{DeeperBind}}},
  booktitle = {2016 {{IEEE International Conference}} on {{Bioinformatics}} and {{Biomedicine}} ({{BIBM}})},
  author = {Hassanzadeh, H. R. and Wang, M. D.},
  year = {2016},
  month = dec,
  pages = {178--183},
  doi = {10/gfxx9g},
  abstract = {Transcription factors (TFs) are macromolecules that bind to cis-regulatory specific sub-regions of DNA promoters and initiate transcription. Finding the exact location of these binding sites (aka motifs) is important in a variety of domains such as drug design and development. To address this need, several in vivo and in vitro techniques have been developed so far that try to characterize and predict the binding specificity of a protein to different DNA loci. The major problem with these techniques is that they are not accurate enough in prediction of the binding affinity and characterization of the corresponding motifs. As a result, downstream analysis is required to uncover the locations where proteins of interest bind. Here, we propose DeeperBind, a long short term recurrent convolutional network for prediction of protein binding specificities with respect to DNA probes. DeeperBind can model the positional dynamics of probe sequences and hence reckons with the contributions made by individual sub-regions in DNA sequences, in an effective way. Moreover, it can be trained and tested on datasets containing varying-length sequences. We apply our pipeline to the datasets derived from protein binding microarrays (PBMs), an in-vitro high-throughput technology for quantification of protein-DNA binding preferences, and present promising results. To the best of our knowledge, this is the most accurate pipeline that can predict binding specificities of DNA sequences from the data produced by high-throughput technologies through utilization of the power of deep learning for feature generation and positional dynamics modeling.},
  keywords = {binding affinity,biology computing,cis-regulatory specific sub-regions,Computer architecture,Convolution,deep learning,DeeperBind,DNA,DNA binding proteins,DNA promoters,drug design,drugs,feature generation,learning (artificial intelligence),long short term recurrent convolutional network,macromolecules,molecular biophysics,Pipelines,positional dynamics modeling,Predictive models,Probes,protein binding microarrays,proteins,Proteins,sequence specificities prediction,transcription factors},
  annotation = {00020},
  file = {/home/will/Zotero/storage/8ZSNDTSH/Hassanzadeh_Wang_2016_DeeperBind.pdf;/home/will/Zotero/storage/Y27B579W/7822515.html}
}

@misc{HomePredictionCenter,
  title = {Home - {{Prediction Center}}},
  howpublished = {http://predictioncenter.org/index.cgi},
  annotation = {00000}
}

@article{joImprovingProteinFold2015,
  title = {Improving {{Protein Fold Recognition}} by {{Deep Learning Networks}}},
  author = {Jo, Taeho and Hou, Jie and Eickholt, Jesse and Cheng, Jianlin},
  year = {2015},
  month = dec,
  journal = {Scientific Reports},
  volume = {5},
  issn = {2045-2322},
  doi = {10/f72x79},
  abstract = {For accurate recognition of protein folds, a deep learning network method (DN-Fold) was developed to predict if a given query-template protein pair belongs to the same structural fold. The input used stemmed from the protein sequence and structural features extracted from the protein pair. We evaluated the performance of DN-Fold along with 18 different methods on Lindahl's benchmark dataset and on a large benchmark set extracted from SCOP 1.75 consisting of about one million protein pairs, at three different levels of fold recognition (i.e., protein family, superfamily, and fold) depending on the evolutionary distance between protein sequences. The correct recognition rate of ensembled DN-Fold for Top 1 predictions is 84.5\%, 61.5\%, and 33.6\% and for Top 5 is 91.2\%, 76.5\%, and 60.7\% at family, superfamily, and fold levels, respectively. We also evaluated the performance of single DN-Fold (DN-FoldS), which showed the comparable results at the level of family and superfamily, compared to ensemble DN-Fold. Finally, we extended the binary classification problem of fold recognition to real-value regression task, which also show a promising performance. DN-Fold is freely available through a web server at http://iris.rnet.missouri.edu/dnfold.},
  pmcid = {PMC4669437},
  pmid = {26634993},
  annotation = {00000},
  file = {/home/will/Zotero/storage/W3R5MFZ5/Jo et al_2015_Improving Protein Fold Recognition by Deep Learning Networks.pdf}
}

@article{jumperHighlyAccurateProtein2021,
  title = {Highly Accurate Protein Structure Prediction with {{AlphaFold}}},
  author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v Z}{\'i}dek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and {Romera-Paredes}, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
  year = {2021},
  month = jul,
  journal = {Nature},
  pages = {1--11},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10/gk7nfp},
  abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1\textendash 4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the 3-D structure that a protein will adopt based solely on its amino acid sequence, the structure prediction component of the `protein folding problem'8, has been an important open research problem for more than 50 years9. Despite recent progress10\textendash 14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even where no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experiment in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
  language = {en},
  annotation = {00000  Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Computational biophysics;Machine learning;Protein structure predictions;Structural biology Subject\_term\_id: computational-biophysics;machine-learning;protein-structure-predictions;structural-biology},
  file = {/home/will/Zotero/storage/BMXY6WNN/Jumper et al_2021_Highly accurate protein structure prediction with AlphaFold.pdf;/home/will/Zotero/storage/FC7Q2LSE/Jumper et al. - 2021 - Highly accurate protein structure prediction with .pdf;/home/will/Zotero/storage/HQAU8TYI/41586_2021_3819_MOESM2_ESM.pdf;/home/will/Zotero/storage/K74B4G5T/s41586-021-03819-2.html}
}

@article{kaurAPROACHESPREDICTIONPROTEIN,
  title = {{{APROACHES TO PREDICTION OF PROTEIN STRUCTURE}}: {{A REVIEW}}},
  author = {Kaur, Er Amanpreet and Sahib, Fatehgarh and Khehra, Dr Baljit Singh},
  volume = {04},
  number = {04},
  pages = {17},
  language = {en},
  annotation = {00000},
  file = {/home/will/Zotero/storage/8FSLIUT5/Kaur et al. - APROACHES TO PREDICTION OF PROTEIN STRUCTURE A RE.pdf}
}

@article{kryshtafovychCriticalAssessmentMethods2019,
  title = {Critical Assessment of Methods of Protein Structure Prediction ({{CASP}})\textemdash{{Round XIII}}},
  author = {Kryshtafovych, Andriy and Schwede, Torsten and Topf, Maya and Fidelis, Krzysztof and Moult, John},
  year = {2019},
  month = dec,
  journal = {Proteins: Structure, Function, and Bioinformatics},
  volume = {87},
  number = {12},
  pages = {1011--1020},
  issn = {0887-3585, 1097-0134},
  doi = {10/ggjr6z},
  language = {en},
  annotation = {00172},
  file = {/home/will/Zotero/storage/FB2TEZVZ/Kryshtafovych et al_2019_Critical assessment of methods of protein structure prediction (CASP)—Round XIII.pdf}
}

@article{kulmanovDeepGOPredictingProtein2018,
  title = {{{DeepGO}}: Predicting Protein Functions from Sequence and Interactions Using a Deep Ontology-Aware Classifier},
  shorttitle = {{{DeepGO}}},
  author = {Kulmanov, Maxat and Khan, Mohammed Asif and Hoehndorf, Robert},
  year = {2018},
  month = feb,
  journal = {Bioinformatics},
  volume = {34},
  number = {4},
  pages = {660--668},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btx624},
  abstract = {AbstractMotivation.  A large number of protein sequences are becoming available through the application of novel high-throughput sequencing technologies. Experi},
  language = {en},
  file = {/home/will/Zotero/storage/DPVS65I8/Kulmanov et al. - 2018 - DeepGO predicting protein functions from sequence.pdf;/home/will/Zotero/storage/FQFQ4FDH/4265461.html}
}

@inproceedings{leeDistogramTranslationRotationinvariant2002,
  title = {Distogram: A Translation- and Rotation-Invariant and Scale-Covariant Signature of a Primitive Shape},
  shorttitle = {Distogram},
  booktitle = {Proceedings of the 9th {{International Conference}} on {{Neural Information Processing}}, 2002. {{ICONIP}} '02.},
  author = {Lee, Geehyuk and Sohn, Misook},
  year = {2002},
  month = nov,
  volume = {4},
  pages = {1847-1851 vol.4},
  doi = {10/bt8wr3},
  abstract = {We propose a new one-dimensional signature of a two-dimensional binary pattern, which we call distogram meaning the histogram of distances between pairs of foreground pixels. A simple test consisting of six roman capital letters is carried out in order to evaluate the discrimination ability of the proposed signature. Also, a pulse-coupled neural network is described as an example of a simple network design that can compute a distogram given a two dimensional binary pattern as an input.},
  keywords = {Artificial neural networks,Biological system modeling,Computer networks,Computer vision,Frequency,Gray-scale,Histograms,Neural networks,Shape,Testing},
  annotation = {00001},
  file = {/home/will/Zotero/storage/7BMN34W5/Lee_Sohn_2002_Distogram.pdf}
}

@article{liuComprehensiveReviewComparison2019,
  title = {A Comprehensive Review and Comparison of Existing Computational Methods for Intrinsically Disordered Protein and Region Prediction},
  author = {Liu, Yumeng and Wang, Xiaolong and Liu, Bin},
  year = {2019},
  month = jan,
  journal = {Briefings in Bioinformatics},
  volume = {20},
  number = {1},
  pages = {330--346},
  issn = {1467-5463},
  doi = {10.1093/bib/bbx126},
  abstract = {Intrinsically disordered proteins and regions are widely distributed in proteins, which are associated with many biological processes and diseases. Accurate prediction of intrinsically disordered proteins and regions is critical for both basic research (such as protein structure and function prediction) and practical applications (such as drug development). During the past decades, many computational approaches have been proposed, which have greatly facilitated the development of this important field. Therefore, a comprehensive and updated review is highly required. In this regard, we give a review on the computational methods for intrinsically disordered protein and region prediction, especially focusing on the recent development in this field. These computational approaches are divided into four categories based on their methodologies, including physicochemical-based method, machine-learning-based method, template-based method and meta method. Furthermore, their advantages and disadvantages are also discussed. The performance of 40 state-of-the-art predictors is directly compared on the target proteins in the task of disordered region prediction in the 10th Critical Assessment of protein Structure Prediction. A more comprehensive performance comparison of 45 different predictors is conducted based on seven widely used benchmark data sets. Finally, some open problems and perspectives are discussed.},
  language = {en},
  annotation = {00000},
  file = {/home/will/Zotero/storage/WWF5PAHM/Liu et al. - 2019 - A comprehensive review and comparison of existing .pdf;/home/will/Zotero/storage/8QA3SFW9/4372408.html}
}

@article{liuDeepRecurrentNeural2017,
  title = {Deep {{Recurrent Neural Network}} for {{Protein Function Prediction}} from {{Sequence}}},
  author = {Liu, Xueliang},
  year = {2017},
  month = jan,
  journal = {arXiv:1701.08318 [cs, q-bio, stat]},
  eprint = {1701.08318},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio, stat},
  abstract = {As high-throughput biological sequencing becomes faster and cheaper, the need to extract useful information from sequencing becomes ever more paramount, often limited by low-throughput experimental characterizations. For proteins, accurate prediction of their functions directly from their primary amino-acid sequences has been a long standing challenge. Here, machine learning using artificial recurrent neural networks (RNN) was applied towards classification of protein function directly from primary sequence without sequence alignment, heuristic scoring or feature engineering. The RNN models containing long-short-term-memory (LSTM) units trained on public, annotated datasets from UniProt achieved high performance for in-class prediction of four important protein functions tested, particularly compared to other machine learning algorithms using sequence-derived protein features. RNN models were used also for out-of-class predictions of phylogenetically distinct protein families with similar functions, including proteins of the CRISPR-associated nuclease, ferritin-like iron storage and cytochrome P450 families. Applying the trained RNN models on the partially unannotated UniRef100 database predicted not only candidates validated by existing annotations but also currently unannotated sequences. Some RNN predictions for the ferritin-like iron sequestering function were experimentally validated, even though their sequences differ significantly from known, characterized proteins and from each other and cannot be easily predicted using popular bioinformatics methods. As sequencing and experimental characterization data increases rapidly, the machine-learning approach based on RNN could be useful for discovery and prediction of homologues for a wide range of protein functions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Biomolecules,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {/home/will/Zotero/storage/2SBESZCD/Liu - 2017 - Deep Recurrent Neural Network for Protein Function.pdf;/home/will/Zotero/storage/GM4953CK/1701.html}
}

@book{lodishMolecularCellBiology2016,
  title = {Molecular {{Cell Biology}}},
  author = {Lodish, H and Berk, A and Kaiser, C and Krieger, M and Bretscher, A and Ploegh, H and Amon, A and Martin, K},
  year = {2016},
  edition = {Eighth},
  publisher = {{W. H. Freeman \& Co.}},
  address = {{New York, NY}},
  isbn = {1-4641-8339-2},
  language = {en},
  file = {/home/will/Zotero/storage/EEIMB4L8/Molecular_Cell_Biology_8th_ed_Lodish_et..pdf}
}

@book{MachineLearningParadigms2018,
  title = {Machine Learning Paradigms},
  year = {2018},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{New York, NY}},
  isbn = {978-3-319-94029-8},
  language = {en},
  annotation = {00000},
  file = {/home/will/Zotero/storage/HSMZSG7R/2018 - Machine learning paradigms.pdf}
}

@incollection{majorekFirstStepsProtein2008,
  title = {First {{Steps}} of {{Protein Structure Prediction}}},
  booktitle = {Prediction of {{Protein Structures}}, {{Functions}}, and {{Interactions}}},
  author = {Majorek, Karolina and Koz{\l}owski, {\L}ukasz and J{\k{a}}kalski, Marcin and Bujnicki, Janusz M.},
  year = {2008},
  pages = {39--62},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9780470741894.ch2},
  abstract = {This chapter contains sections titled: Introduction Definition of Secondary Structure and Its Assignment for Known Protein Structures Prediction of Secondary Structure and Solvent Accessibility for Water-soluble Proteins Prediction of Secondary Structure for Transmembrane Proteins Prediction of Supersecondary Structure Disorder Prediction Prediction of Long-range Contacts between Amino Acid Residues Summary Acknowledgements References},
  copyright = {Copyright \textcopyright{} 2009 John Wiley \& Sons, Ltd},
  isbn = {978-0-470-74189-4},
  language = {en},
  keywords = {Dictionary of Secondary Structure in Proteins (DSSP),KAKSI,multiple sequence information,P-SEA,PALSSE methods,protein structure prediction steps,secondary structure assignment - STRIDE,secondary structure prediction and knowledge-based structure prediction,secondary structure prediction software,SECSTR,SEGNO,supersecondary structure prediction},
  annotation = {00002},
  file = {/home/will/Zotero/storage/ZB6RTHBR/Majorek.pdf}
}

@inproceedings{martinoSupervisedApproachesProtein2018,
  title = {Supervised {{Approaches}} for {{Protein Function Prediction}} by {{Topological Data Analysis}}},
  booktitle = {2018 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Martino, A. and Rizzi, A. and Mascioli, F. M. F.},
  year = {2018},
  month = jul,
  pages = {1--8},
  doi = {10/gftjxm},
  abstract = {Topological Data Analysis is a novel approach, useful whenever data can be described by topological structures such as graphs. The aim of this paper is to investigate whether such tool can be used in order to define a set of descriptors useful for pattern recognition and machine learning tasks. Specifically, we consider a supervised learning problem with the final goal of predicting proteins' physiological function starting from their respective residue contact network. Indeed, folded proteins can effectively be described by graphs, making them a useful case-study for assessing Topological Data Analysis effectiveness concerning pattern recognition tasks. Experiments conducted on a subset of the Escherichia coli proteome using two different classification systems show that descriptors derived from Topological Data Analysis - namely, the Betti numbers sequence - lead to classification performances comparable with descriptors derived from widely-known centrality measures, as concerns the protein function prediction problem. Further benchmarking tests suggest the presence of some information despite the heavy compression intrinsic to the protein-to-Betti numbers casting.},
  keywords = {biology computing,data analysis,Data analysis,escherichia coli proteome,Feature extraction,graph theory,learning (artificial intelligence),machine learning tasks,pattern recognition,Pattern recognition,pattern recognition tasks,protein function prediction problem,protein-to-Betti numbers casting,proteins,Proteins,proteomics,supervised learning problem,Support vector machines,Task analysis,Three-dimensional displays,topological data analysis},
  file = {/home/will/Zotero/storage/FW8SGSEF/Martino et al. - Supervised Approaches for Protein Function Predict.pdf;/home/will/Zotero/storage/49NE5FHG/8489307.html}
}

@article{maticzkaGraphProtModelingBinding2014,
  title = {{{GraphProt}}: Modeling Binding Preferences of {{RNA}}-Binding Proteins},
  shorttitle = {{{GraphProt}}},
  author = {Maticzka, Daniel and Lange, Sita J. and Costa, Fabrizio and Backofen, Rolf},
  year = {2014},
  month = jan,
  journal = {Genome Biology},
  volume = {15},
  number = {1},
  pages = {R17},
  issn = {1474-760X},
  doi = {10/gbfsxs},
  abstract = {We present GraphProt, a computational framework for learning sequence- and structure-binding preferences of RNA-binding proteins (RBPs) from high-throughput experimental data. We benchmark GraphProt, demonstrating that the modeled binding preferences conform to the literature, and showcase the biological relevance and two applications of GraphProt models. First, estimated binding affinities correlate with experimental measurements. Second, predicted Ago2 targets display higher levels of expression upon Ago2 knockdown, whereas control targets do not. Computational binding models, such as those provided by GraphProt, are essential for predicting RBP binding sites and affinities in all tissues. GraphProt is freely available at http://www.bioinf.uni-freiburg.de/Software/GraphProt.},
  file = {/home/will/Zotero/storage/4DDFQWRW/Maticzka et al_2014_GraphProt.pdf;/home/will/Zotero/storage/Y4B3CUQF/gb-2014-15-1-r17.html}
}

@incollection{murrayProteins2017,
  title = {Proteins},
  booktitle = {Pharmacognosy},
  author = {Murray, J.E. and Laurieri, N. and Delgoda, R.},
  year = {2017},
  pages = {477--494},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-12-802104-0.00024-X},
  isbn = {978-0-12-802104-0},
  language = {en},
  annotation = {03105},
  file = {/home/will/Zotero/storage/88B92E72/Murray et al. - 2017 - Proteins.pdf}
}

@techreport{nornProteinSequenceDesign2020,
  type = {Preprint},
  title = {Protein Sequence Design by Explicit Energy Landscape Optimization},
  author = {Norn, Christoffer and Wicky, Basile I. M. and Juergens, David and Liu, Sirui and Kim, David and Koepnick, Brian and Anishchenko, Ivan and Players, Foldit and Baker, David and Ovchinnikov, Sergey},
  year = {2020},
  month = jul,
  institution = {{Biophysics}},
  doi = {10.1101/2020.07.23.218917},
  abstract = {The protein design problem is to identify an amino acid sequence which folds to a desired structure. Given Anfinsen's thermodynamic hypothesis of folding, this can be recast as finding an amino acid sequence for which the lowest energy conformation is that structure. As this calculation involves not only all possible amino acid sequences but also all possible structures, most current approaches focus instead on the more tractable problem of finding the lowest energy amino acid sequence for the desired structure, often checking by protein structure prediction in a second step that the desired structure is indeed the lowest energy conformation for the designed sequence, and discarding the in many cases large fraction of designed sequences for which this is not the case. Here we show that by backpropagating gradients through the trRosetta structure prediction network from the desired structure to the input amino acid sequence, we can directly optimize over all possible amino acid sequences and all possible structures, and in one calculation explicitly design amino acid sequences predicted to fold into the desired structure and not any other. We find that trRosetta calculations, which consider the full conformational landscape, can be more effective than Rosetta single point energy estimations in predicting folding and stability of de novo designed proteins. We compare sequence design by landscape optimization to the standard fixed backbone sequence design methodology in Rosetta, and show that the results of the former, but not the latter, are sensitive to the presence of competing low-lying states. We show further that more funneled energy landscapes can be designed by combining the strengths of the two approaches: the low resolution trRosetta model serves to disfavor alternative states, and the high resolution Rosetta model, to create a deep energy minimum at the design target structure.},
  language = {en},
  annotation = {00006},
  file = {/home/will/Zotero/storage/JG5BPL8Q/Norn et al. - 2020 - Protein sequence design by explicit energy landsca.pdf}
}

@article{panPredictionRNAproteinSequence2018,
  title = {Prediction of {{RNA}}-Protein Sequence and Structure Binding Preferences Using Deep Convolutional and Recurrent Neural Networks},
  author = {Pan, Xiaoyong and Rijnbeek, Peter and Yan, Junchi and Shen, Hong-Bin},
  year = {2018},
  month = jul,
  journal = {BMC Genomics},
  volume = {19},
  number = {1},
  pages = {511},
  issn = {1471-2164},
  doi = {10.1186/s12864-018-4889-1},
  abstract = {RNA regulation is significantly dependent on its binding protein partner, known as the RNA-binding proteins (RBPs). Unfortunately, the binding preferences for most RBPs are still not well characterized. Interdependencies between sequence and secondary structure specificities is challenging for both predicting RBP binding sites and accurate sequence and structure motifs detection.},
  file = {/home/will/Zotero/storage/RKAQKPEV/Pan et al. - 2018 - Prediction of RNA-protein sequence and structure b.pdf;/home/will/Zotero/storage/HCKRML8P/s12864-018-4889-1.html}
}

@article{panRNAproteinBindingMotifs2017,
  title = {{{RNA}}-Protein Binding Motifs Mining with a New Hybrid Deep Learning Based Cross-Domain Knowledge Integration Approach},
  author = {Pan, Xiaoyong and Shen, Hong-Bin},
  year = {2017},
  month = feb,
  journal = {BMC Bioinformatics},
  volume = {18},
  number = {1},
  pages = {136},
  issn = {1471-2105},
  doi = {10.1186/s12859-017-1561-8},
  abstract = {RNAs play key roles in cells through the interactions with proteins known as the RNA-binding proteins (RBP) and their binding motifs enable crucial understanding of the post-transcriptional regulation of RNAs. How the RBPs correctly recognize the target RNAs and why they bind specific positions is still far from clear. Machine learning-based algorithms are widely acknowledged to be capable of speeding up this process. Although many automatic tools have been developed to predict the RNA-protein binding sites from the rapidly growing multi-resource data, e.g. sequence, structure, their domain specific features and formats have posed significant computational challenges. One of current difficulties is that the cross-source shared common knowledge is at a higher abstraction level beyond the observed data, resulting in a low efficiency of direct integration of observed data across domains. The other difficulty is how to interpret the prediction results. Existing approaches tend to terminate after outputting the potential discrete binding sites on the sequences, but how to assemble them into the meaningful binding motifs is a topic worth of further investigation.},
  file = {/home/will/Zotero/storage/HFMZGGK3/Pan and Shen - 2017 - RNA-protein binding motifs mining with a new hybri.pdf;/home/will/Zotero/storage/BBSINACT/s12859-017-1561-8.html}
}

@article{parkDeepLearningRegulatory2015,
  title = {Deep Learning for Regulatory Genomics},
  author = {Park, Yongjin and Kellis, Manolis},
  year = {2015},
  month = aug,
  journal = {Nature Biotechnology},
  volume = {33},
  number = {8},
  pages = {825--826},
  issn = {1546-1696},
  doi = {10.1038/nbt.3313},
  abstract = {Computational modeling of DNA and RNA targets of regulatory proteins is improved by a deep-learning approach.},
  copyright = {2015 Nature Publishing Group},
  language = {en},
  file = {/home/will/Zotero/storage/NJKLGBE8/Park_Kellis_2015_Deep learning for regulatory genomics.pdf;/home/will/Zotero/storage/DQL5LLR3/nbt.html}
}

@misc{PDB101LearnGuide,
  title = {{{PDB101}}: {{Learn}}: {{Guide}} to {{Understanding PDB Data}}: {{Beginner}}'s {{Guide}} to {{PDB Structures}} and the {{PDBx}}/{{mmCIF Format}}},
  shorttitle = {{{PDB101}}},
  journal = {RCSB: PDB-101},
  abstract = {PDBx/mmCIF forms the basis of wwPDB data deposition, annotation, and archiving of PDB structure data.   This PDB-101 resource is an introductory guide.},
  howpublished = {https://pdb101.rcsb.org/learn/guide-to-understanding-pdb-data/beginner\%E2\%80\%99s-guide-to-pdb-structures-and-the-pdbx-mmcif-format},
  annotation = {00000}
}

@article{porterExtantFoldswitchingProteins2018,
  title = {Extant Fold-Switching Proteins Are Widespread},
  author = {Porter, Lauren L. and Looger, Loren L.},
  year = {2018},
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {23},
  pages = {5968--5973},
  issn = {0027-8424, 1091-6490},
  doi = {10/gdppkn},
  abstract = {A central tenet of biology is that globular proteins have a unique 3D structure under physiological conditions. Recent work has challenged this notion by demonstrating that some proteins switch folds, a process that involves remodeling of secondary structure in response to a few mutations (evolved fold switchers) or cellular stimuli (extant fold switchers). To date, extant fold switchers have been viewed as rare byproducts of evolution, but their frequency has been neither quantified nor estimated. By systematically and exhaustively searching the Protein Data Bank (PDB), we found {$\sim$}100 extant fold-switching proteins. Furthermore, we gathered multiple lines of evidence suggesting that these proteins are widespread in nature. Based on these lines of evidence, we hypothesized that the frequency of extant fold-switching proteins may be underrepresented by the structures in the PDB. Thus, we sought to identify other putative extant fold switchers with only one solved conformation. To do this, we identified two characteristic features of our {$\sim$}100 extant fold-switching proteins, incorrect secondary structure predictions and likely independent folding cooperativity, and searched the PDB for other proteins with similar features. Reassuringly, this method identified dozens of other proteins in the literature with indication of a structural change but only one solved conformation in the PDB. Thus, we used it to estimate that 0.5\textendash 4\% of PDB proteins switch folds. These results demonstrate that extant fold-switching proteins are likely more common than the PDB reflects, which has implications for cell biology, genomics, and human health.},
  copyright = {Copyright \textcopyright{} 2018 the Author(s). Published by PNAS.. This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
  language = {en},
  pmid = {29784778},
  keywords = {conformational diversity,metamorphic proteins,protein fold switching,protein function,protein structure},
  annotation = {00007},
  file = {/home/will/Zotero/storage/GIMGD324/Porter_Looger_2018_Extant fold-switching proteins are widespread.pdf}
}

@article{quangDanQHybridConvolutional2016,
  title = {{{DanQ}}: A Hybrid Convolutional and Recurrent Deep Neural Network for Quantifying the Function of {{DNA}} Sequences},
  shorttitle = {{{DanQ}}},
  author = {Quang, Daniel and Xie, Xiaohui},
  year = {2016},
  month = jun,
  journal = {Nucleic Acids Research},
  volume = {44},
  number = {11},
  pages = {e107},
  issn = {1362-4962},
  doi = {10.1093/nar/gkw226},
  abstract = {Modeling the properties and functions of DNA sequences is an important, but challenging task in the broad field of genomics. This task is particularly difficult for non-coding DNA, the vast majority of which is still poorly understood in terms of function. A powerful predictive model for the function of non-coding DNA can have enormous benefit for both basic science and translational research because over 98\% of the human genome is non-coding and 93\% of disease-associated variants lie in these regions. To address this need, we propose DanQ, a novel hybrid convolutional and bi-directional long short-term memory recurrent neural network framework for predicting non-coding function de novo from sequence. In the DanQ model, the convolution layer captures regulatory motifs, while the recurrent layer captures long-term dependencies between the motifs in order to learn a regulatory 'grammar' to improve predictions. DanQ improves considerably upon other models across several metrics. For some regulatory markers, DanQ can achieve over a 50\% relative improvement in the area under the precision-recall curve metric compared to related models. We have made the source code available at the github repository http://github.com/uci-cbcl/DanQ.},
  language = {eng},
  pmcid = {PMC4914104},
  pmid = {27084946},
  keywords = {DNA,Genome-Wide Association Study,Genomics,Humans,Neural Networks (Computer),Polymorphism; Single Nucleotide,Quantitative Trait Loci,ROC Curve,Sequence Analysis; DNA,Software,Web Browser},
  annotation = {00145},
  file = {/home/will/Zotero/storage/2RKVQ4QX/Quang_Xie_2016_DanQ.pdf}
}

@misc{rubieraAlphaFoldHereWhat,
  title = {{{AlphaFold}} 2 Is Here: What's behind the Structure Prediction Miracle | {{Oxford Protein Informatics Group}}},
  shorttitle = {{{AlphaFold}} 2 Is Here},
  author = {Rubiera, Carlos Outeiral},
  language = {en-US},
  annotation = {00000},
  file = {/home/will/Zotero/storage/6E77KBIU/alphafold-2-is-here-whats-behind-the-structure-prediction-miracle.html}
}

@article{seniorImprovedProteinStructure2020,
  ids = {seniorImprovedProteinStructure2020a},
  title = {Improved Protein Structure Prediction Using Potentials from Deep Learning},
  author = {Senior, Andrew W. and Evans, Richard and Jumper, John and Kirkpatrick, James and Sifre, Laurent and Green, Tim and Qin, Chongli and {\v Z}{\'i}dek, Augustin and Nelson, Alexander W. R. and Bridgland, Alex and Penedones, Hugo and Petersen, Stig and Simonyan, Karen and Crossan, Steve and Kohli, Pushmeet and Jones, David T. and Silver, David and Kavukcuoglu, Koray and Hassabis, Demis},
  year = {2020},
  month = jan,
  journal = {Nature},
  volume = {577},
  number = {7792},
  pages = {706--710},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10/ggjfcc},
  abstract = {Protein structure prediction can be used to determine the three-dimensional shape of a protein from its amino acid sequence1. This problem is of fundamental importance as the structure of a protein largely determines its function2; however, protein structures can be difficult to determine experimentally. Considerable progress has recently been made by leveraging genetic information. It is possible to infer which amino acid residues are in contact by analysing covariation in homologous sequences, which aids in the prediction of protein structures3. Here we show that we can train a neural network to make accurate predictions of the distances between pairs of residues, which convey more information about the structure than contact predictions. Using this information, we construct a potential of mean force4 that can accurately describe the shape of a protein. We find that the resulting potential can be optimized by a simple gradient descent algorithm to generate structures without complex sampling procedures. The resulting system, named AlphaFold, achieves high accuracy, even for sequences with fewer homologous sequences. In the recent Critical Assessment of Protein Structure Prediction5 (CASP13)\textemdash a blind assessment of the state of the field\textemdash AlphaFold created high-accuracy structures (with template modelling (TM) scores6 of 0.7 or higher) for 24 out of 43 free modelling domains, whereas the next best method, which used sampling and contact information, achieved such accuracy for only 14 out of 43 domains. AlphaFold represents a considerable advance in protein-structure prediction. We expect this increased accuracy to enable insights into the function and malfunction of proteins, especially in cases for which no structures for homologous proteins have been experimentally determined7.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
  language = {en},
  annotation = {00823  Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Machine learning;Protein structure predictions Subject\_term\_id: machine-learning;protein-structure-predictions},
  file = {/home/will/Zotero/storage/DLCU794H/41586_2019_1923_MOESM2_ESM.pdf;/home/will/Zotero/storage/G76FLSNF/old.pdf;/home/will/Zotero/storage/XEV28LHL/10.1038@s41586-019-1923-7.pdf}
}

@article{seoDeepFamDeepLearning2018,
  title = {{{DeepFam}}: Deep Learning Based Alignment-Free Method for Protein Family Modeling and Prediction},
  shorttitle = {{{DeepFam}}},
  author = {Seo, Seokjun and Oh, Minsik and Park, Youngjune and Kim, Sun},
  year = {2018},
  month = jul,
  journal = {Bioinformatics},
  volume = {34},
  number = {13},
  pages = {i254-i262},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/bty275},
  abstract = {AbstractMotivation.  A large number of newly sequenced proteins are generated by the next-generation sequencing technologies and the biochemical function assign},
  language = {en},
  file = {/home/will/Zotero/storage/W8BSBIFK/Seo et al. - 2018 - DeepFam deep learning based alignment-free method.pdf;/home/will/Zotero/storage/HDXN6U9G/5045722.html}
}

@misc{SpatialTransformationMatrices,
  title = {Spatial {{Transformation Matrices}}},
  howpublished = {https://www.brainvoyager.com/bv/doc/UsersGuide/CoordsAndTransforms/SpatialTransformationMatrices.html},
  annotation = {00002}
}

@incollection{staporMachineLearningMethods2019,
  title = {Machine {{Learning Methods}} for the {{Protein Fold Recognition Problem}}},
  booktitle = {Machine {{Learning Paradigms}}: {{Advances}} in {{Data Analytics}}},
  author = {Stapor, Katarzyna and {Roterman-Konieczna}, Irena and Fabian, Piotr},
  editor = {Tsihrintzis, George A. and Sotiropoulos, Dionisios N. and Jain, Lakhmi C.},
  year = {2019},
  series = {Intelligent {{Systems Reference Library}}},
  pages = {101--127},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-94030-4_5},
  abstract = {The protein fold recognition problem is crucial in bioinformatics. It is usually solved using sequence comparison methods but when proteins similar in structure share little in the way of sequence homology they fail and machine learning methods are used to predict the structure of the protein. The imbalance of the data sets, the number of outliers and the high number of classes make the task very complex. We try to explain the methodology for building classifiers for protein fold recognition and to cover all the major results in this field.},
  isbn = {978-3-319-94030-4},
  language = {en},
  keywords = {\#nosource,Classifier,Features,Protein fold recognition,Supervised learning algorithm},
  file = {/home/will/Zotero/storage/AL94XUF8/Stapor et al_2019_Machine Learning Methods for the Protein Fold Recognition Problem.pdf}
}

@article{sunSequencebasedPredictionProtein2017,
  title = {Sequence-Based Prediction of Protein Protein Interaction Using a Deep-Learning Algorithm},
  author = {Sun, Tanlin and Zhou, Bo and Lai, Luhua and Pei, Jianfeng},
  year = {2017},
  month = may,
  journal = {BMC Bioinformatics},
  volume = {18},
  number = {1},
  pages = {277},
  issn = {1471-2105},
  doi = {10.1186/s12859-017-1700-2},
  abstract = {Protein-protein interactions (PPIs) are critical for many biological processes. It is therefore important to develop accurate high-throughput methods for identifying PPI to better understand protein function, disease occurrence, and therapy design. Though various computational methods for predicting PPI have been developed, their robustness for prediction with external datasets is unknown. Deep-learning algorithms have achieved successful results in diverse areas, but their effectiveness for PPI prediction has not been tested.},
  file = {/home/will/Zotero/storage/LKEMGLS5/Sun et al. - 2017 - Sequence-based prediction of protein protein inter.pdf;/home/will/Zotero/storage/HLBIXKSV/s12859-017-1700-2.html}
}

@misc{tianOverviewProteinFold2018,
  type = {Text},
  title = {An {{Overview}} on {{Protein Fold Classification}} via {{Machine Learning Approach}}},
  author = {Tian, Xiaoyu and Chen, Daozheng and Gao, Jun},
  year = {2018},
  month = apr,
  doi = {doi/10.217/1570164614666171030160312},
  howpublished = {https://www.ingentaconnect.com/contentone/ben/cp/2018/00000015/00000002/art00004},
  language = {en},
  file = {/home/will/Zotero/storage/SA6B8R2W/art00004.html}
}

@article{trabelsiComprehensiveEvaluationDeep2019,
  title = {Comprehensive {{Evaluation}} of {{Deep Learning Architectures}} for {{Prediction}} of {{DNA}}/{{RNA Sequence Binding Specificities}}},
  author = {Trabelsi, Ameni and Chaabane, Mohamed and Hur, Asa Ben},
  year = {2019},
  month = jan,
  abstract = {Motivation: Deep learning architectures have recently demonstrated their power in predicting DNA- and RNA-binding specificities. Existing methods fall into three classes: Some are based on Convolutional Neural Networks (CNNs), others use Recurrent Neural Networks (RNNs), and others rely on hybrid architectures combining CNNs and RNNs. However, based on existing studies it is still unclear which deep learning architecture is achieving the best performance. Thus an in-depth analysis and evaluation of the different methods is needed to fully evaluate their relative. Results: In this study, We present a systematic exploration of various deep learning architectures for predicting DNA- and RNA-binding specificities. For this purpose, we present deepRAM, an end-to-end deep learning tool that provides an implementation of novel and previously proposed architectures; its fully automatic model selection procedure allows us to perform a fair and unbiased comparison of deep learning architectures. We find that an architecture that uses k-mer embedding to represent the sequence, a convolutional layer and a recurrent layer, outperforms all other methods in terms of model accuracy. Our work provides guidelines that will assist the practitioner in choosing the best architecture for the task at hand, and provides some insights on the differences between the models learned by convolutional and recurrent networks. In particular, we find that although recurrent networks improve model accuracy, this comes at the expense of a loss in the interpretability of the features learned by the model. Availability and implementation: The source code for deepRAM is available at https://github.com/MedChaabane/deepRAM},
  language = {en},
  annotation = {00000},
  file = {/home/will/Zotero/storage/95BZD3HV/Trabelsi et al_2019_Comprehensive Evaluation of Deep Learning Architectures for Prediction of.pdf;/home/will/Zotero/storage/3XW9DT8Z/1901.html}
}

@article{uzielaProQ3DImprovedModel2017,
  title = {{{ProQ3D}}: Improved Model Quality Assessments Using Deep Learning},
  shorttitle = {{{ProQ3D}}},
  author = {Uziela, Karolis and Men{\'e}ndez Hurtado, David and Shu, Nanjiang and Wallner, Bj{\"o}rn and Elofsson, Arne},
  year = {2017},
  month = may,
  journal = {Bioinformatics},
  volume = {33},
  number = {10},
  pages = {1578--1580},
  issn = {1367-4803},
  doi = {10/f3t5pz},
  abstract = {Protein quality assessment is a long-standing problem in bioinformatics. For more thana decade we have developed state-of-art predictors by carefully selecting and optimising inputs toa machine learning method. The correlation has increased from 0.60 in ProQ to 0.81 in ProQ2 and0.85 in ProQ3 mainly by adding a large set of carefully tuned descriptions of a protein. Here, weshow that a substantial improvement can be obtained using exactly the same inputs as in ProQ2 orProQ3 but replacing the support vector machine by a deep neural network. This improves thePearson correlation to 0.90 (0.85 using ProQ2 input features).Availability and Implementation: ProQ3D is freely available both as a webserver and a stand-alone},
  language = {en},
  annotation = {00033},
  file = {/home/will/Zotero/storage/WXCGB8WH/Uziela et al_2017_ProQ3D.pdf;/home/will/Zotero/storage/Z4YSBZ94/2801464.html}
}

@article{valastyanMechanismsProteinfoldingDiseases2014,
  title = {Mechanisms of Protein-Folding Diseases at a Glance},
  author = {Valastyan, J. S. and Lindquist, S.},
  year = {2014},
  month = jan,
  journal = {Disease Models \& Mechanisms},
  volume = {7},
  number = {1},
  pages = {9--14},
  issn = {1754-8403, 1754-8411},
  doi = {10/f5rpzx},
  abstract = {For a protein to function appropriately, it must first achieve its proper conformation and location within the crowded environment inside the cell. Multiple chaperone systems are required to fold proteins correctly. In addition, degradation pathways participate by destroying improperly folded proteins. The intricacy of this multisystem process provides many opportunities for error. Furthermore, mutations cause misfolded, nonfunctional forms of proteins to accumulate. As a result, many pathological conditions are fundamentally rooted in the proteinfolding problem that all cells must solve to maintain their function and integrity. Here, to illustrate the breadth of this phenomenon, we describe five examples of protein-misfolding events that can lead to disease: improper degradation, mislocalization, dominant-negative mutations, structural alterations that establish novel toxic functions, and amyloid accumulation. In each case, we will highlight current therapeutic options for battling such diseases.},
  language = {en},
  annotation = {00166},
  file = {/home/will/Zotero/storage/KQCZLQCB/Valastyan and Lindquist - 2014 - Mechanisms of protein-folding diseases at a glance.pdf}
}

@article{wainbergDeepLearningBiomedicine2018,
  title = {Deep Learning in Biomedicine},
  author = {Wainberg, Michael and Merico, Daniele and Delong, Andrew and Frey, Brendan J},
  year = {2018},
  month = sep,
  journal = {Nature Biotechnology},
  volume = {36},
  number = {9},
  pages = {829--838},
  issn = {1087-0156, 1546-1696},
  doi = {10/gd4ws2},
  language = {en},
  file = {/home/will/Zotero/storage/YBUHC6C5/Wainberg et al. - 2018 - Deep learning in biomedicine.pdf}
}

@article{weiRecentProgressMachine2016,
  title = {Recent {{Progress}} in {{Machine Learning}}-{{Based Methods}} for {{Protein Fold Recognition}}},
  author = {Wei, Leyi and Zou, Quan},
  year = {2016},
  month = dec,
  journal = {International Journal of Molecular Sciences},
  volume = {17},
  number = {12},
  pages = {2118},
  doi = {10.3390/ijms17122118},
  abstract = {Knowledge on protein folding has a profound impact on understanding the heterogeneity and molecular function of proteins, further facilitating drug design. Predicting the 3D structure (fold) of a protein is a key problem in molecular biology. Determination of the fold of a protein mainly relies on molecular experimental methods. With the development of next-generation sequencing techniques, the discovery of new protein sequences has been rapidly increasing. With such a great number of proteins, the use of experimental techniques to determine protein folding is extremely difficult because these techniques are time consuming and expensive. Thus, developing computational prediction methods that can automatically, rapidly, and accurately classify unknown protein sequences into specific fold categories is urgently needed. Computational recognition of protein folds has been a recent research hotspot in bioinformatics and computational biology. Many computational efforts have been made, generating a variety of computational prediction methods. In this review, we conduct a comprehensive survey of recent computational methods, especially machine learning-based methods, for protein fold recognition. This review is anticipated to assist researchers in their pursuit to systematically understand the computational recognition of protein folds.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  language = {en},
  keywords = {computational method,machine learning,protein fold recognition},
  file = {/home/will/Zotero/storage/WA64V7X2/Wei and Zou - 2016 - Recent Progress in Machine Learning-Based Methods .pdf;/home/will/Zotero/storage/2CYL8FCG/2118.html}
}

@article{xieSelftrainingNoisyStudent2020,
  title = {Self-Training with {{Noisy Student}} Improves {{ImageNet}} Classification},
  author = {Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V.},
  year = {2020},
  month = jun,
  journal = {arXiv:1911.04252 [cs, stat]},
  eprint = {1911.04252},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {We present Noisy Student Training, a semi-supervised learning approach that works well even when labeled data is abundant. Noisy Student Training achieves 88.4\% top-1 accuracy on ImageNet, which is 2.0\% better than the state-of-the-art model that requires 3.5B weakly labeled Instagram images. On robustness test sets, it improves ImageNet-A top-1 accuracy from 61.0\% to 83.7\%, reduces ImageNet-C mean corruption error from 45.7 to 28.3, and reduces ImageNet-P mean flip rate from 27.8 to 12.2. Noisy Student Training extends the idea of self-training and distillation with the use of equal-or-larger student models and noise added to the student during learning. On ImageNet, we first train an EfficientNet model on labeled images and use it as a teacher to generate pseudo labels for 300M unlabeled images. We then train a larger EfficientNet as a student model on the combination of labeled and pseudo labeled images. We iterate this process by putting back the student as the teacher. During the learning of the student, we inject noise such as dropout, stochastic depth, and data augmentation via RandAugment to the student so that the student generalizes better than the teacher. Models are available at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet. Code is available at https://github.com/google-research/noisystudent.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {00558},
  file = {/home/will/Zotero/storage/8BPHX9I8/Xie et al_2020_Self-training with Noisy Student improves ImageNet classification.pdf}
}

@article{yangLearnedProteinEmbeddings2018,
  title = {Learned Protein Embeddings for Machine Learning},
  author = {Yang, Kevin K. and Wu, Zachary and Bedbrook, Claire N. and Arnold, Frances H.},
  year = {2018},
  month = aug,
  journal = {Bioinformatics},
  volume = {34},
  number = {15},
  pages = {2642--2648},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/bty178},
  abstract = {AbstractMotivation.  Machine-learning models trained on protein sequences and their measured functions can infer biological properties of unseen sequences witho},
  language = {en},
  file = {/home/will/Zotero/storage/3W2W9W78/4951834.html}
}

@article{yueDeepLearningGenomics2018,
  title = {Deep {{Learning}} for {{Genomics}}: {{A Concise Overview}}},
  shorttitle = {Deep {{Learning}} for {{Genomics}}},
  author = {Yue, Tianwei and Wang, Haohan},
  year = {2018},
  month = feb,
  journal = {arXiv:1802.00810 [cs, q-bio]},
  eprint = {1802.00810},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio},
  abstract = {This data explosion driven by advancements in genomic research, such as high-throughput sequencing techniques, is constantly challenging conventional methods used in genomics. In parallel with the urgent demand for robust algorithms, deep learning has succeeded in a variety of fields such as vision, speech, and text processing. Yet genomics entails unique challenges to deep learning since we are expecting from deep learning a superhuman intelligence that explores beyond our knowledge to interpret the genome. A powerful deep learning model should rely on insightful utilization of task-specific knowledge. In this paper, we briefly discuss the strengths of different deep learning models from a genomic perspective so as to fit each particular task with a proper deep architecture, and remark on practical considerations of developing modern deep learning architectures for genomics. We also provide a concise review of deep learning applications in various aspects of genomic research, as well as pointing out current challenges and potential research directions for future genomics applications.},
  archiveprefix = {arXiv},
  language = {en},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,Quantitative Biology - Genomics},
  file = {/home/will/Zotero/storage/4UC2U3T5/Yue and Wang - 2018 - Deep Learning for Genomics A Concise Overview.pdf;/home/will/Zotero/storage/KH6LNBXR/Yue and Wang - 2018 - Deep Learning for Genomics A Concise Overview.skim}
}

@article{zengConvolutionalNeuralNetwork2016,
  title = {Convolutional Neural Network Architectures for Predicting {{DNA}}\textendash Protein Binding},
  author = {Zeng, Haoyang and Edwards, Matthew D. and Liu, Ge and Gifford, David K.},
  year = {2016},
  month = jun,
  journal = {Bioinformatics},
  volume = {32},
  number = {12},
  pages = {i121-i127},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btw255},
  abstract = {Abstract.  Motivation: Convolutional neural networks (CNN) have outperformed conventional methods in modeling the sequence specificity of DNA\textendash protein binding. Y},
  language = {en},
  file = {/home/will/Zotero/storage/V57RRDLA/Zeng et al. - 2016 - Convolutional neural network architectures for pre.pdf;/home/will/Zotero/storage/VWDPW5FR/2240609.html}
}

@inproceedings{zhangPredictionRNAproteinInteractions2018,
  title = {Prediction of {{RNA}}-Protein Interactions with Distributed Feature Representations and a Hybrid Deep Model},
  booktitle = {{{ICIMCS}}},
  author = {Zhang, Kaiming and Xiao, Yiqun and Pan, Xiaoyong and Yang, Yang},
  year = {2018},
  doi = {10.1145/3240876.3240912},
  abstract = {The interactions between proteins and RNAs play essential roles in many important biological processes. While the detection of protein-RNA interaction by biological experiments is a laborious and time-consuming task, computational prediction tools are highly in need. The prediction performance of the computational tools rely on two factors, namely feature representation of RNA sequences and classification models. In the existing methods, statistical features or one-hot vectors are adopted, and most of the classifiers are traditional machine learning models, while the distributed representation and flexible deep learning architectures have not been exploited. Therefore, in this study, we represent RNA sequences by continuous distributed features, and propose a hybrid deep learning architecture, which combines both CNN and RNN. The experiments are conducted on 31 benchmark datasets, corresponding to 31 RNA-binding-proteins. The results show that the new method achieves obvious advantages against the existing methods on most of the datasets.},
  keywords = {Artificial neural network,Benchmark (computing),Computation,Computational complexity theory,Deep learning,Experiment,Interaction,Machine learning,One-hot,Statistical classification}
}


